{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TorchMetricLogger import TorchMetricLogger as TML\n",
    "from TorchMetricLogger import TmlMetric, TmlMetricFunction, TMLBinaryAccuracy, TMLDiceCoefficient\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tml = TML()\n",
    "\n",
    "p_1d = torch.ones((10, 5))\n",
    "y_1d = torch.ones((10, 5))\n",
    "\n",
    "p_1d[:, 3:] = 0\n",
    "\n",
    "p_2d = torch.ones((10, 5, 5))\n",
    "y_2d = torch.ones((10, 5, 5))\n",
    "\n",
    "p_2d[0] = 0\n",
    "\n",
    "w = torch.ones(10)\n",
    "w[0] = 0.5\n",
    "\n",
    "tml(\n",
    "    meow=TmlMetric(p_1d, y_1d, metric_class=TMLBinaryAccuracy), \n",
    "    miau=TmlMetric(p_1d, y_1d, metric_class=TMLDiceCoefficient),\n",
    "    wuff=TmlMetric(p_2d, y_2d, weights=w, metric_class=TMLDiceCoefficient)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tml.metrics[\"meow\"].reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([0.03846154, 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "        dtype=float32),\n",
       "  array([0.5, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ], dtype=float32)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tml.metrics[\"wuff\"].partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94939274"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tml.metrics[\"wuff\"].reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777910232544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tml.metrics[\"miau\"].reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tml = TML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the (weighted) mean, usefull for loss functions\n",
    "class TMLF1(TmlMetricFunction):\n",
    "    def __call__(self, metric):\n",
    "        if metric.weights is None:\n",
    "            metric.weights = np.ones(metric.predictions.size)\n",
    "    \n",
    "        super().__call__(metric)\n",
    "        \n",
    "    def calculate(self, metric):\n",
    "        tp = np.sum(((metric.gold_labels >= 0.5) * (metric.predictions >= 0.5)) * metric.weights)\n",
    "        fp = np.sum(((metric.gold_labels < 0.5) * (metric.predictions >= 0.5)) * metric.weights)\n",
    "        fn = np.sum(((metric.gold_labels >= 0.5) * (metric.predictions < 0.5)) * metric.weights)\n",
    "        \n",
    "        return [tp, fp, fn]\n",
    "\n",
    "    def reduction_function(self):\n",
    "        tp = self.partial[:, 0]\n",
    "        fp = self.partial[:, 1]\n",
    "        fn = self.partial[:, 2]\n",
    "\n",
    "        return np.mean(tp / (tp + (fp + fn)/2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.] [2.] [0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "p = np.array([1,1,1,1,0,0])\n",
    "l = np.array([1,1,1,1,1,1])\n",
    "\n",
    "tml(\n",
    "    meow=TmlMetric(p, l, metric_class=TMLF1)\n",
    ")\n",
    "\n",
    "tml.on_batch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tml.metrics[\"meow\"].partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tml.metrics[\"meow\"].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(l, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corcodan",
   "language": "python",
   "name": "corcodan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
